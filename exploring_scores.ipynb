{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Out-of-distribution detection\n",
    "\n",
    "From the paper [Energy-based Out-of-distribution Detection](http://arxiv.org/abs/2010.03759). Let's explore the folder structure, the models and the available scripts and extract what we need for our ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from anomaly_scores.energy import energy_anomaly_score\n",
    "from anomaly_scores.max_logit import max_logit_anomaly_score\n",
    "from anomaly_scores.softmax import max_softmax_anomaly_score\n",
    "from anomaly_scores.vim_scores import VIM\n",
    "from energy_ood.CIFAR.models.wrn import WideResNet\n",
    "from energy_ood.utils.svhn_loader import SVHN\n",
    "from util.get_ood_score import get_ood_score_for_multiple_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We are using the Wide ResNet as in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideResNet(depth=40, num_classes=10, widen_factor=2, dropRate=0.3)\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"energy_ood/CIFAR/snapshots/pretrained/cifar10_wrn_pretrained_epoch_99.pt\",\n",
    "        map_location=torch.device(\"cpu\"),\n",
    "    )\n",
    ")\n",
    "model.eval()\n",
    "_ = model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "Let's start with replicating the results from the paper. First, with the SVHN data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = []\n",
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean, std)]\n",
    ")\n",
    "\n",
    "id_data = datasets.CIFAR10(\"data/cifar10\", train=False, transform=test_transform)\n",
    "id_loader = torch.utils.data.DataLoader(\n",
    "    id_data, batch_size=200, shuffle=False, num_workers=2, pin_memory=True\n",
    ")\n",
    "loaders.append((\"CIFAR10\", id_loader))\n",
    "\n",
    "\n",
    "ood_data = SVHN(\n",
    "    root=\"data/svhn/\",\n",
    "    split=\"test\",\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(mean, std)]  # trn.Resize(32),\n",
    "    ),\n",
    "    download=False,\n",
    ")\n",
    "ood_loader = torch.utils.data.DataLoader(\n",
    "    ood_data, batch_size=200, shuffle=True, num_workers=2, pin_memory=True\n",
    ")\n",
    "ood_num_examples = len(loaders[0][1].dataset) // 5\n",
    "loaders.append((\"SVHN\", ood_loader))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Scores\n",
    "Let's compare the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vim = VIM(id_loader, model)\n",
    "\n",
    "scores = [\n",
    "    (\"MaxLogit\", max_logit_anomaly_score),\n",
    "    (\"MaxSoftmax\", max_softmax_anomaly_score),\n",
    "    (\"Energy\", energy_anomaly_score),\n",
    "    (\"VIM\", vim.compute_anomaly_score),\n",
    "]\n",
    "\n",
    "all_anomaly_results = {\"WRN\": {}}\n",
    "\n",
    "for name, score in scores:\n",
    "    all_anomaly_results[\"WRN\"][name] = get_ood_score_for_multiple_datasets(\n",
    "        loaders,\n",
    "        model,\n",
    "        score,\n",
    "        is_using=\"last\" if not name == \"VIM\" else \"last_penultimate\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      WRN |     SVHN     |     AVG     \n",
      "=======================================================\n",
      "                 MaxLogit |    90.58%    |    90.58%   \n",
      "               MaxSoftmax |    92.03%    |    92.03%   \n",
      "                   Energy |    91.83%    |    91.83%   \n",
      "                      VIM |   *94.75%    |   *94.75%   \n",
      "\n",
      "\n",
      "* highlights the maximum AUROC Score for an OOD Dataset\n"
     ]
    }
   ],
   "source": [
    "from util.display_results import compare_all_results\n",
    "\n",
    "compare_all_results(all_anomaly_results, loaders)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, only the virutal logit matching score achieves an improved score compared to the others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "activation-ood-VPh-MuUw-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
